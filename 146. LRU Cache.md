Tags: [[HashTable]], [[Linked List]], [[Design]], [[Doubly-Linked List]]
Difficulty: [[Medium]]
## Problem
Design a data structure that follows the constraints of a **[Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU)**.

Implement the `LRUCache` class:

- `LRUCache(int capacity)` Initialize the LRU cache with **positive** size `capacity`.
- `int get(int key)` Return the value of the `key` if the key exists, otherwise return `-1`.
- `void put(int key, int value)` Update the value of the `key` if the `key` exists. Otherwise, add the `key-value` pair to the cache. If the number of keys exceeds the `capacity` from this operation, **evict** the least recently used key.

The functions `get` and `put` must each run in `O(1)` average time complexity.

**Example 1:**
**Input**
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]
**Output**
[null, null, null, 1, null, -1, null, -1, 3, 4]

**Explanation**
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // cache is {1=1}
lRUCache.put(2, 2); // cache is {1=1, 2=2}
lRUCache.get(1);    // return 1
lRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is {1=1, 3=3}
lRUCache.get(2);    // returns -1 (not found)
lRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}
lRUCache.get(1);    // return -1 (not found)
lRUCache.get(3);    // return 3
lRUCache.get(4);    // return 4

**Constraints:**
- `1 <= capacity <= 3000`
- `0 <= key <= 104`
- `0 <= value <= 105`
- At most `2 * 105` calls will be made to `get` and `put`.

## Solution
You're asked to design a **Least Recently Used (LRU) Cache** with two operations:
- `get(key)` – Return the value if the key exists, otherwise return `-1`.
- `put(key, value)` – Insert or update the value. If capacity is exceeded, remove the least recently used item.

#### Key Requirements:
- Both operations must run in **O(1) time**.

### Step-by-Step Thought Process

### 1. **Understand what “Least Recently Used” means**
You need to track the **order** of usage:
- When an item is **accessed** (via `get` or `put`), it becomes the **most recently used**.
- When the cache is full and a new item needs to be added, you evict the **least recently used** item.

### 2. **Need for O(1) access and update**
This suggests combining:
- A **hash map** for fast key access.
- A **doubly linked list** to maintain usage order. 

###  Key Data Structures
1. **Hash Map (`dict`)**
    - Maps `key` → `node`.
    - Enables O(1) access to the cache item.
2. **Doubly Linked List**
    - Each node holds `(key, value)`.
    - Head = most recently used.
    - Tail = least recently used.
    - Supports O(1) insertion and deletion.

### Algorithm Overview
- **`get(key)`**:
    - If key in cache:
        - Move the node to the **head** (mark as recently used).
        - Return the value.
    - Else, return `-1`.
- **`put(key, value)`**
    - If key exists:
        - Update the value.
        - Move node to **head**.
    - Else:
        - If at capacity:
            - Remove the node at the **tail** (least recently used).
        - Insert new node at **head**.
### Tips for Implementation
- Write a helper function for:
    - Removing a node from the linked list.
    - Adding a node to the front.
- Use **dummy head and dummy tail** to simplify edge case handling in the doubly linked list.
- Ensure the doubly linked list nodes store both key and value so you can remove keys from the map when evicted.

```python
class Node:
	def __init__(self, key=0, val=0):
		self.key, self.val = key, val
		self.prev = self.next = None
  
class LRUCache:
	def __init__(self, capacity: int):
		self.capacity = capacity
		self.cache = {}
		  
		self.head, self.tail = Node(), Node()
		self.head.next, self.tail.prev = self.tail, self.head
	  
	def _remove(self, node):
		prev_node, next_node = node.prev, node.next
		prev_node.next = next_node
		next_node.prev = prev_node
	  
	def _insert(self, node):
		node.prev, node.next = self.head, self.head.next
		self.head.next.prev = node
		self.head.next = node
	
	  
	def get(self, key: int) -> int:
		if key in self.cache:
			node = self.cache[key]
			self._remove(node)
			self._insert(node)
			return node.val
		return -1
	  
	def put(self, key: int, value: int) -> None:
		if key in self.cache:
			node = self.cache[key]
			node.val = value
			self._remove(node)
			self._insert(node)
		else:
			if len(self.cache) == self.capacity:
				# Remove lru item
				lru = self.tail.prev
				self._remove(lru)
				del self.cache[lru.key]
			  
			# Add new node
			new_node = Node(key, value)
			self.cache[key] = new_node
			self._insert(new_node)

  
# Your LRUCache object will be instantiated and called as such:
# obj = LRUCache(capacity)
# param_1 = obj.get(key)

# obj.put(key,value)
```

![[imgs/Pasted image 20250609172415.png]]
